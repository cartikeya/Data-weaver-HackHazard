# Data-weaver-HackHazard


![github-submission-banner](https://github.com/user-attachments/assets/a1493b84-e4e2-456e-a791-ce35ee2bcf2f)

# ğŸš€ Project Title

> DataWeave is an AI-powered web scraping and data processing tool that lets users extract information from any website, format it into CSV/JSON, and query it using multiple LLMs like Groq and GPT. It supports both direct URL scraping and prompt-based intelligent search, giving users full control over how data is gathered, cleaned, and analyzedâ€”without writing a single line of code.

---

## ğŸ“Œ Problem Statement

Select the problem statement number and title from the official list given in Participant Manual.

**Example:**  
**Problem Statement 1 â€“ Weave AI Magic with groq**

---

## ğŸ¯ Objective

DataWeave simplifies web data extraction using AI. It helps users quickly scrape, summarize, and structure data from websites, prompts, images, or audio â€” all powered by Groq.
Built for analysts, developers, and researchers, it turns unstructured content into usable insights and datasets within seconds.

---

## ğŸ§  Team & Approach

### Team Name:  
`scrape squad`

### Team Members:  
- Bhavesh - Full Stack & AI Integration
- Akshita - Frontend Developer (React, Tailwind)
- Cartikeya â€“ Python Developer & UI Integration
- Mythilli â€“ ML & Backend Logic


### Your Approach:  
- We chose this problem because web data is powerful but often messy and hard to access. We wanted to make scraping and dataset creation as easy as typing a prompt.
- Major challenges included handling dynamic content scraping, integrating Groqâ€™s multimodal API, and converting user input into structured datasets.
- During development, we pivoted from a basic scraper to a full dataset builder â€” including text, image, and audio handling. A key breakthrough was successfully combining prompt-based scraping with Groq for rich, meaningful results.

---

## ğŸ› ï¸ Tech Stack

### Core Technologies Used:
- Frontend: HTML, CSS, JavaScript, EJS, Tailwind CSS
- Backend: Node.js, Express.js
- Database: None (uses file system and in-memory storage)
- APIs: Groq LLMs, Puppeteer, Python subprocess (image scraping).

### Sponsor Technologies Used :
- âœ… **Groq:** _Used Groqâ€™s ultra-fast LLMs to process and summarize scraped text, generate insights from user prompts, and convert multimedia content (text, image, audio) into structured datasets in real time_  
---

## âœ¨ Key Features

Highlight the most important features of your project:

- âœ… Prompt-Based Scraping: Users can simply type a prompt (e.g., â€œMS Dhoni retirement newsâ€) and get summarized results using Groq.
- âœ… Multimodal Dataset Builder: Supports building datasets from text, image, and audio inputs â€” processed into downloadable formats.
- âœ… Live Web Scraping via URL: Extract content from any URL with dynamic control using a slider for content depth.
- âœ… JSON & ZIP Export Options: One-click export of scraped or generated data into .json or zipped .txt datasets.
- âœ… Mobile-Friendly UI: Built to be responsive and accessible across devices for quick testing.

Add images, GIFs, or screenshots if helpful!

---

## ğŸ“½ï¸ Demo & Deliverables

- **Demo Video Link:** [Paste YouTube or Loom link here]  

---

## âœ… Tasks & Bonus Checklist

- âœ… **All members of the team completed the mandatory task - Followed at least 2 of our social channels and filled the form** (Details in Participant Manual)  
- âœ… **All members of the team completed Bonus Task 1 - Sharing of Badges and filled the form (2 points)**  (Details in Participant Manual)
- âœ… **All members of the team completed Bonus Task 2 - Signing up for Sprint.dev and filled the form (3 points)**  (Details in Participant Manual)

---

## ğŸ§ª How to Run the Project

### Requirements:
-	Node.js (v16 or above)
-	Python 3.10+
-	Groq API Key (youâ€™ll need to create a .env file)
-	Git (to clone the repo)

### Local Setup:
```bash

# 1. Clone the repository
git clone https://github.com/cartikeya/Data-weaver-HackHazard.git
cd Data-weaver-HackHazard

# 2. Install Node dependencies
npm install

# 3. Install Python dependencies
pip install -r requirements.txt

# 4. Add your API key
touch .env
# Paste this inside .env:
# GROQ_API_KEY=your_key_here

# 5. Run the project
node app.js
```

---

## ğŸ§¬ Future Scope



- ğŸ”— Multisite Scraping â€“ Add support to scrape multiple websites in parallel for broader data extraction.
- ğŸ§  Custom AI Models â€“ Let users plug in their own Groq API keys or models for tailored insights.
- ğŸ’¾ Database Integration â€“ Store user-generated datasets for history, reuse, or analytics.
- ğŸŒ Export Formats â€“ Add support for exporting in CSV, XLSX, or custom API endpoints.
- ğŸ“± Progressive Web App (PWA) â€“ Turn the platform into a mobile-friendly offline-first tool.
- ğŸŒ Multilingual Support â€“ Enable scraping and summarization in multiple languages.
- ğŸ›¡ï¸ Authentication & Privacy â€“ Add user logins, encryption, and file auto-deletion policies.

---

## ğŸ“ Resources / Credits

- Groq LLMs â€“ Used for ultra-fast text summarization and dataset generation.
- Puppeteer â€“ Headless browser automation for URL-based scraping.
- icrawler â€“ For scraping images from Google.
- BeautifulSoup4 â€“ HTML parsing for web content.
- python-docx â€“ Used to extract and process .docx files.
- Adm-Zip â€“ Node.js package to zip scraped data.


â¸»

## ğŸ™Œ Acknowledgements:
- Hackathon mentors and organizers for guidance and challenge framing.
- Open-source contributors for maintaining the packages used in this project.

---

## ğŸ Final Words

Akshita-
Bhavesh-
Mythili-
cartikeya-

---
